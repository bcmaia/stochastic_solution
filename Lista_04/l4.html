<!DOCTYPE html>
<html>
<head>
<title>l4.md</title>
<meta http-equiv="Content-type" content="text/html;charset=UTF-8">

<style>
/* https://github.com/microsoft/vscode/blob/master/extensions/markdown-language-features/media/markdown.css */
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

body {
	font-family: var(--vscode-markdown-font-family, -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif);
	font-size: var(--vscode-markdown-font-size, 14px);
	padding: 0 26px;
	line-height: var(--vscode-markdown-line-height, 22px);
	word-wrap: break-word;
}

#code-csp-warning {
	position: fixed;
	top: 0;
	right: 0;
	color: white;
	margin: 16px;
	text-align: center;
	font-size: 12px;
	font-family: sans-serif;
	background-color:#444444;
	cursor: pointer;
	padding: 6px;
	box-shadow: 1px 1px 1px rgba(0,0,0,.25);
}

#code-csp-warning:hover {
	text-decoration: none;
	background-color:#007acc;
	box-shadow: 2px 2px 2px rgba(0,0,0,.25);
}

body.scrollBeyondLastLine {
	margin-bottom: calc(100vh - 22px);
}

body.showEditorSelection .code-line {
	position: relative;
}

body.showEditorSelection .code-active-line:before,
body.showEditorSelection .code-line:hover:before {
	content: "";
	display: block;
	position: absolute;
	top: 0;
	left: -12px;
	height: 100%;
}

body.showEditorSelection li.code-active-line:before,
body.showEditorSelection li.code-line:hover:before {
	left: -30px;
}

.vscode-light.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(0, 0, 0, 0.15);
}

.vscode-light.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(0, 0, 0, 0.40);
}

.vscode-light.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-dark.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 255, 255, 0.4);
}

.vscode-dark.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 255, 255, 0.60);
}

.vscode-dark.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-high-contrast.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 160, 0, 0.7);
}

.vscode-high-contrast.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 160, 0, 1);
}

.vscode-high-contrast.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

img {
	max-width: 100%;
	max-height: 100%;
}

a {
	text-decoration: none;
}

a:hover {
	text-decoration: underline;
}

a:focus,
input:focus,
select:focus,
textarea:focus {
	outline: 1px solid -webkit-focus-ring-color;
	outline-offset: -1px;
}

hr {
	border: 0;
	height: 2px;
	border-bottom: 2px solid;
}

h1 {
	padding-bottom: 0.3em;
	line-height: 1.2;
	border-bottom-width: 1px;
	border-bottom-style: solid;
}

h1, h2, h3 {
	font-weight: normal;
}

table {
	border-collapse: collapse;
}

table > thead > tr > th {
	text-align: left;
	border-bottom: 1px solid;
}

table > thead > tr > th,
table > thead > tr > td,
table > tbody > tr > th,
table > tbody > tr > td {
	padding: 5px 10px;
}

table > tbody > tr + tr > td {
	border-top: 1px solid;
}

blockquote {
	margin: 0 7px 0 5px;
	padding: 0 16px 0 10px;
	border-left-width: 5px;
	border-left-style: solid;
}

code {
	font-family: Menlo, Monaco, Consolas, "Droid Sans Mono", "Courier New", monospace, "Droid Sans Fallback";
	font-size: 1em;
	line-height: 1.357em;
}

body.wordWrap pre {
	white-space: pre-wrap;
}

pre:not(.hljs),
pre.hljs code > div {
	padding: 16px;
	border-radius: 3px;
	overflow: auto;
}

pre code {
	color: var(--vscode-editor-foreground);
	tab-size: 4;
}

/** Theming */

.vscode-light pre {
	background-color: rgba(220, 220, 220, 0.4);
}

.vscode-dark pre {
	background-color: rgba(10, 10, 10, 0.4);
}

.vscode-high-contrast pre {
	background-color: rgb(0, 0, 0);
}

.vscode-high-contrast h1 {
	border-color: rgb(0, 0, 0);
}

.vscode-light table > thead > tr > th {
	border-color: rgba(0, 0, 0, 0.69);
}

.vscode-dark table > thead > tr > th {
	border-color: rgba(255, 255, 255, 0.69);
}

.vscode-light h1,
.vscode-light hr,
.vscode-light table > tbody > tr + tr > td {
	border-color: rgba(0, 0, 0, 0.18);
}

.vscode-dark h1,
.vscode-dark hr,
.vscode-dark table > tbody > tr + tr > td {
	border-color: rgba(255, 255, 255, 0.18);
}

</style>

<style>
/* Tomorrow Theme */
/* http://jmblog.github.com/color-themes-for-google-code-highlightjs */
/* Original theme - https://github.com/chriskempson/tomorrow-theme */

/* Tomorrow Comment */
.hljs-comment,
.hljs-quote {
	color: #8e908c;
}

/* Tomorrow Red */
.hljs-variable,
.hljs-template-variable,
.hljs-tag,
.hljs-name,
.hljs-selector-id,
.hljs-selector-class,
.hljs-regexp,
.hljs-deletion {
	color: #c82829;
}

/* Tomorrow Orange */
.hljs-number,
.hljs-built_in,
.hljs-builtin-name,
.hljs-literal,
.hljs-type,
.hljs-params,
.hljs-meta,
.hljs-link {
	color: #f5871f;
}

/* Tomorrow Yellow */
.hljs-attribute {
	color: #eab700;
}

/* Tomorrow Green */
.hljs-string,
.hljs-symbol,
.hljs-bullet,
.hljs-addition {
	color: #718c00;
}

/* Tomorrow Blue */
.hljs-title,
.hljs-section {
	color: #4271ae;
}

/* Tomorrow Purple */
.hljs-keyword,
.hljs-selector-tag {
	color: #8959a8;
}

.hljs {
	display: block;
	overflow-x: auto;
	color: #4d4d4c;
	padding: 0.5em;
}

.hljs-emphasis {
	font-style: italic;
}

.hljs-strong {
	font-weight: bold;
}
</style>

<style>
/*
 * Markdown PDF CSS
 */

 body {
	font-family: -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif, "Meiryo";
	padding: 0 12px;
}

pre {
	background-color: #f8f8f8;
	border: 1px solid #cccccc;
	border-radius: 3px;
	overflow-x: auto;
	white-space: pre-wrap;
	overflow-wrap: break-word;
}

pre:not(.hljs) {
	padding: 23px;
	line-height: 19px;
}

blockquote {
	background: rgba(127, 127, 127, 0.1);
	border-color: rgba(0, 122, 204, 0.5);
}

.emoji {
	height: 1.4em;
}

code {
	font-size: 14px;
	line-height: 19px;
}

/* for inline code */
:not(pre):not(.hljs) > code {
	color: #C9AE75; /* Change the old color so it seems less like an error */
	font-size: inherit;
}

/* Page Break : use <div class="page"/> to insert page break
-------------------------------------------------------- */
.page {
	page-break-after: always;
}

</style>

<script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
</head>
<body>
  <script>
    mermaid.initialize({
      startOnLoad: true,
      theme: document.body.classList.contains('vscode-dark') || document.body.classList.contains('vscode-high-contrast')
          ? 'dark'
          : 'default'
    });
  </script>
<h1 id="lista-4--processos-estoc%C3%A1sticos">Lista 4 ~ Processos Estocásticos</h1>
<p>Bernardo Maia Coelho, 12542481</p>
<h2 id="quest%C3%A3o-01">Questão 01</h2>
<p>Sejam X e Y variáveis aleatórias independentes, com distribuições de Poisson
de parâmetros α e β. Mostre que a variável X + Y tem uma distribuição de
Poisson de parâmetro α + β.</p>
<hr>
<p>(Método 1) Tenho dúvidas sobre esse método, mas, seja
$$ X \sim Poisson(\alpha)  \hspace{5em} Y \sim Poisson(\beta)$$
Seja
$$ Z(t) = X(t) + Y(t) $$</p>
<p>$$ E[Z(t)] = E[X(t) + Y(t)]$$</p>
<p>Dado X e Y independentes, vale
$$ E[Z(t)] = E[X(t) + Y(t)] = E[X(t)] + E[Y(t)]$$
$$ E[Z(t)] = \mu t = E[X(t)] + E[Y(t)] = \alpha t + \beta t $$
$$ \mu t = \alpha t + \beta t $$
$$ \mu = \alpha + \beta  $$</p>
<p>(Método 2) Alternativamente, podemos analisar o caso
$$ Z(t) = 0 \iff X(t) = 0, Y(t) = 0 $$
$$ Pr { Z(t) = 0 } = Pr { X(t) = 0 } \cdot  Pr { Y(t) = 0 } $$
$$ \frac{e^{-\mu t} * (\mu t)^0}{0!}
= \frac{e^{-\alpha t} * (\alpha t)^0}{0!}
\cdot \frac{e^{-\beta t} * (\beta t)^0}{0!}
$$
$$ e^{-\mu t}
= e^{-\alpha t}
\cdot e^{-\beta t}
$$</p>
<p>$$ e^{-\mu t}
= e^{-\alpha t}
\cdot e^{-\beta t}
$$</p>
<p>$$ e^{-\mu t} = e^{(-\alpha t) + (-\beta t)} $$
$$ e^{-\mu t} = e^{-(\alpha + \beta) t} $$</p>
<p>E, assim, concluímos que Z segue uma distribuição de poisson
de taxa $\mu = \alpha + \beta$.</p>
<h2 id="quest%C3%A3o-02">Questão 02</h2>
<p>Defeitos ocorrem ao longo de um cabo de fibra óptica de acordo com um
processo de Poisson com taxa λ = 0.1 defeitos por Km.</p>
<h3 id="a-qual-%C3%A9-a-probabilidade-de-que-n%C3%A3o-ocorra-nenhum-defeito-nos-primeiros-2-km">(a) Qual é a probabilidade de que não ocorra nenhum defeito nos primeiros 2 Km?</h3>
<p>Bom, podemos considerar $t &gt; 0$ sendo t um intervalo medido em km.
$$ Pr { N(2) = 0 }
= \frac {
e^{-0.1 \cdot 2}(0.1 \cdot 2)^0
} { 0! }
= e^{-0.2}
$$</p>
<p>$$ Pr { N(2) = 0 }
= e^{-0.2}
\approx 0.8187307530779818
\approx 0.819
$$</p>
<h3 id="b-sabendo-que-n%C3%A3o-ocorreu-nenhum-defeito-nos-primeiros-2-km-calcule-a-probabilidade-de-que-nenhum-defeito-ocorra-entre-o-segundo-e-terceiro-km">(b) Sabendo que não ocorreu nenhum defeito nos primeiros 2 Km, calcule a probabilidade de que nenhum defeito ocorra entre o segundo e terceiro Km.</h3>
<p>$$ Pr { N(3) - N(2) = 0 | N(2) = 0 }
= Pr { N(3 - 2) = 0 | N(2) = 0 }
= Pr { N(1) = 0 | N(2) = 0 }
$$</p>
<p>$$ Pr { N(1) = 0 | N(2) = 0 }
= \frac {
Pr { N(1) = 0 | N(2) = 0 } \cdot Pr {N(2) = 0 }
} {
Pr {N(2) = 0 }
}
$$</p>
<p>$$ Pr { N(1) = 0 } = e^{-0.1} $$
$$ Pr { N(2) = 0 } = e^{-0.2} $$</p>
<p>$$ Pr { N(1) = 0 | N(2) = 0 }
= \frac{
e^{-0.1} e^{-0.2}
} {e^{-0.2}}
= \frac{e^{-0.3}} {e^{-0.2}}
= e^{-0.1}
\approx 0.9048374180359595
\approx 0.905
$$</p>
<p><br><br></p>
<h2 id="quest%C3%A3o-03">Questão 03</h2>
<p>Clientes chegam a uma certa loja de acordo com um processo de Poisson
com taxa λ = 4 clientes por hora. Sabendo que a loja abre às 9:00h, qual é a
probabilidade de que exatamente um cliente chegue até às 9:30h e um total de
cinco chegue até às 11:30h?</p>
<hr>
<p>Queremos calcular
$$ Pr{ N(0.5) = 1, N(2.5) = 5} $$</p>
<p>Note que não se trata de intervalos disjuntos, então, é preciso aplicar a
propriedade de incrementos independentes.</p>
<p>$$ Pr{ N(0.5) = 1, N(2.5) = 5}
= Pr{ N(0.5) = 1, N(2.5) - N(0.5) = 5 - 1}
= Pr{ N(0.5) = 1 } \cdot Pr { N(2) = 4 }
$$</p>
<p>$$ Pr{ N(0.5) = 1 }
= \frac{e^{-4 \cdot 0.5} (4 \cdot 0.5)^1}{1!}
= 2 e^{-2}
$$</p>
<p>$$ Pr{ N(2) = 4 }
= \frac{e^{-4 \cdot 2} (4 \cdot 2)^4}{4!}
= \frac{8^4e^{-8} }{24}
$$</p>
<p>$$ Pr{ N(0.5) = 1, N(2.5) = 5}
= 2 e^{-2} \cdot \frac{8^4e^{-8} }{24}
= \frac{8^4e^{-10} }{12}
\approx 0.01549650935892817
\approx 0.015
$$</p>
<blockquote>
<p>.
$$ Pr{ N(0.5) = 1, N(2.5) = 5} \approx 0.015 $$
.</p>
</blockquote>
<p><br><br></p>
<h2 id="quest%C3%A3o-04">Questão 04</h2>
<p>Mostre que o número de eventos que ocorrem num intervalo de tempo $(0, t]$
para um processo de Poisson é consequência da lei dos eventos raros.
Em outras palavras, mostre que a distribuição binomial com parâmetros $n$ e $p$
converge para a distribuição de Poisson com parâmetro $\lambda$ conforme
$n \to \infty$ e $p \to \infty$, de forma que $np$ permaneça constante.</p>
<hr>
<p>A lei dos eventos raros estipula que o limite de um Processo de Bernoulli com
baixa probabilidade e grande quantidade de ocorrências (quando $n$ tende ao
infinito) tende a um processo de poisson.
Podemos provar isso da seguinte maneira:</p>
<p>Dado uma discretização do tempo em intervalos de extensão $h = \frac 1 n$.
Partimos da definição da probabilidade $p$ como
$$ p = Pr{N(h) = 1} = \lambda h \cdot O(h)$$</p>
<p>De acordo com a distribuição binomial, vale que
$$ Pr { N = k } = \binom {n} {k} p^k (1 - p)^{n-k} $$</p>
<p>Sendo que $N$ aqui representa o número de sucessos.
Substituindo o valor de p, chegamos em
$$ Pr{ N = k }
= \frac {n!} {(n-k)!k!}
,,     	(\lambda h \cdot O(h))^k
,, (1 - \lambda h \cdot O(h)) ^ {n-k}
$$</p>
<p>$$ \lim _{n \to \infty} Pr{ N = k }
= \lim _{n \to \infty}
\frac {n!} {(n-k)!k!}
,,     	(\lambda h \cdot O(h))^k
,, (1 - \lambda h \cdot O(h)) ^ {n-k}
$$</p>
<p>$$
\lim _{n \to \infty} Pr{ N = k } =
\lim _{h \to 0} \frac{
n \cdot (n-1) \cdot (n-2) \dots \cancel{(n-k)!}
}{
\cancel{(n-k)!} \cdot k!
}
[\lambda h + O(h)]^k \cdot [1 - \lambda h + O(h)]^{n - k}
$$</p>
<p>$$ n(n - 1)(n-2) \dots (n - k - 1) $$
$$
\lim _{h \to 0} \frac{
n \cdot (n-1) \cdot (n-2) \dots \cancel{(n-k)!}
}{
\cancel{(n-k)!} \cdot k!
}
=
\lim _{h \to 0}
n \cdot n(1 - \frac{1}{n})
\cdot n(1 - \frac{2}{n})
\dots n(1 - \frac{k - 1}{n})
=  n^k
$$</p>
<p>Termos como $ 1 / n $ e $t/n$ tendem a zero quando n tende a infinito, logo
$$
\lim _{n \to \infty} Pr{ N = k }
= \frac{n^k}{k!}
\cdot [\frac{(\lambda t)^k}{n^k}]
\cdot [1 - \frac{\lambda t}{n}]
\cdot \frac{1}{(1-  \frac{\lambda t}{n})^k}
$$</p>
<p>Simplificando e removendo termos que tendem a zero:
$$
\lim _{n \to \infty} Pr{ N = k }
= \frac{\cancel{n^k}}{k!}
\cdot \left[ \frac{(\lambda t)^k}{\cancel{n^k}} \right]
\cdot \left( 1 - \frac{\lambda t}{n} \right)
\cdot \frac{1}{(1-  \cancel{\frac{\lambda t}{n}})^k}
$$</p>
<p>Dado que
$$ \lim_{x \to \infty} 1 + \frac x n = e^x$$</p>
<p>Logo,
$$
\lim _{n \to \infty} Pr{ N = k }
= \frac{1}{k!}
\cdot \left[ \frac{(\lambda t)^k}{1} \right]
\cdot \left( 1 - \frac{\lambda t}{n} \right)
= \frac{e^{-\lambda y} (\lambda t)^k}{k!}
$$</p>
<h2 id="quest%C3%A3o-05">Questão 05</h2>
<p>Considere um processo de Poisson de taxa λ eventos por unidade de tempo.
Seja N(t) o número de eventos que ocorrem até no intervalo (0, t].
Considere o intervalo de tempo fixo (s, t], onde s &lt; t.
Determine a probabilidade condicional P{N(t) = n + k|N(s) = n}
e o valor esperado E[N(t)N(s)].</p>
<p>$$ Pr{ N(t) = n + k | N(s) = n }
= Pr{ N(t) - N(s) = n + k - n | N(s) = n }
= Pr{ N(t-s) = k| N(s) = n }
$$</p>
<p>$$ Pr{ N(t) = n + k | N(s) = n }
= \frac {
Pr{ N(t-s) = k} \cdot \cancel{Pr{ N(s) = n}}
} {
\cancel{Pr{ N(s) = n}}
}
$$</p>
<p>$$ Pr{ N(t-s) = k}
= \frac {
e^{-\lambda (t-s)} [\lambda (t-s)]^k
} {
k!
}
$$</p>
<p>Assim, chegamos a</p>
<blockquote>
<p>.
$$ Pr{ N(t) = n + k | N(s) = n }
= \frac {
e^{-\lambda (t-s)} [\lambda (t-s)]^k
} {
k!
}
$$
.</p>
</blockquote>
<p>Para calcular o valor esperado $E[N(t)N(s)]$, podemos usar a fórmula
$$ E[N(t)] = \lambda t $$</p>
<p>Como $s &lt; t$ e $N(t) = N(s) + N(t) - N(s)$, vale
$$ E[N(t)N(s)] = E{ N(s) [N(s) + N(t) - N(s)]} $$
$$ E[N(t)N(s)] = E[N(s)]E[N(t) - N(s)] + E^2[N(s)]$$
$$ E[N(s)^2] = \lambda s (t - s)\lambda + \lambda s + (\lambda s)^2 $$</p>
<p>Simplificando
$$ E[N(s)^2] = ts\lambda^2 -s^2\lambda^2 + \lambda s + \lambda^2 s^2  $$</p>
<blockquote>
<p>.
$$ E[N(s)^2] = ts\lambda^2 + \lambda s  $$
.</p>
</blockquote>
<p><br> <br></p>
<h2 id="quest%C3%A3o-06">Questão 06</h2>
<p>Suponha que pacotes SMTP chegam a um servidor de e-mails de acordo com um
processo de Poisson com intensidade λ = 2. Seja N(t) o número de mensagens
que chegam até o tempo t. Determine as seguintes probabilidades:</p>
<h3 id="a-pn1--2">(a) P{N(1) = 2}</h3>
<p>$$ Pr { N(1) = 2 } = \frac{e^{-2 \cdot 1} (2 \cdot 1)^2}{2!} $$
$$ Pr { N(1) = 2 } = \frac{e^{-2} 2^2}{2} = 2e^{-2}
\approx 0.2706705664732254 $$
$$ Pr { N(1) = 2 } \approx 0.271 $$</p>
<h3 id="b-pn1--2-e-n3--6">(b) P{N(1) = 2 e N(3) = 6}</h3>
<p>$$ Pr { N(1) = 2, N(3) = 6 }
= Pr { N(1) = 2, N(3) - N(1) = 6 - 2 }
$$</p>
<p>$$ Pr { N(1) = 2, N(3) = 6 }
= Pr { N(1) = 2 } Pr { N(2) = 4 }
$$</p>
<p>$$ Pr { N(2) = 4 } = \frac{e^{-2 \cdot 2} (2 \cdot 2)^4}{4!}
= \frac{e^{-4} 4^4}{24} = e^{-4} \cdot \frac{4^4}{24}
$$</p>
<p>$$ Pr { N(1) = 2, N(3) = 6 }
= 2e^{-2} \cdot e^{-4} \cdot \frac{16}{24}
\approx 0.052880046435549
$$</p>
<p>$$ Pr { N(1) = 2, N(3) = 6 } \approx 0.053 $$</p>
<h3 id="c-pn1--2n3--6">(c) P{N(1) = 2|N(3) = 6}</h3>
<p>$$ Pr{N(1) = 2|N(3) = 6} = Pr{N(1) = 2| N(3) - N(1) = 6 - 2 } $$</p>
<p>$$ Pr{N(1) = 2| N(2) = 4 } = \frac{
Pr{N(1) = 2} \cdot Pr{N(2) = 4}
} {
Pr{N(3) = 6 }
}
$$</p>
<p>$$ Pr{N(3) = 6 }
= \frac {e^{-2 \cdot 3} (2 \cdot 3)^6} {6!}
= \frac {e^{-6} 6^6} {6!}
$$</p>
<p>$$ Pr{N(1) = 2| N(2) = 4 } = \frac{
2e^{-2} \cdot e^{-4} \cdot \frac{4^4}{24}
} {</p>
<pre><code>}
= 2e^{-2} \cdot e^{-4} \cdot \frac{4^4}{24} \cdot \frac {6!} {e^{-6} 6^6}
</code></pre>
<p>$$</p>
<p>$$ Pr{N(1) = 2|N(3) = 6} \approx 0.3292181069958848 $$
$$ Pr{N(1) = 2|N(3) = 6} \approx 0.329 $$</p>
<h3 id="d-pn3--6n1--2">(d) P{N(3) = 6|N(1) = 2}</h3>
<p>$$ Pr{N(3) = 6|N(1) = 2}
= Pr{N(3-1) = 6-2}
= Pr{N(2) = 4}
$$</p>
<p>$$ Pr{N(3) = 6|N(1) = 2}
= \frac {e^{-4}(4)^4} {4!}
\approx 0.19536681481316465
$$</p>
<p>$$ Pr{N(3) = 6|N(1) = 2} \approx 0.195 $$</p>
<p><br><br></p>
<h2 id="quest%C3%A3o-07">Questão 07</h2>
<p>Uma certa teoria cientı́fica sugere que erros na divisão celular ocorrem de
acordo comum processo de Poisson com taxa 2.5 erros por dia. Uma célula morre
quando 196 erros ocorrem. Assumindo que essa teoria está correta, encontre:</p>
<h3 id="a-o-tempo-m%C3%A9dio-de-vida-de-uma-c%C3%A9lula">(a) O tempo médio de vida de uma célula</h3>
<p>Seja $\lambda = 2.5$</p>
<p>O tempo médio até que certa quantidade de eventos ocorre de um
processo de poisson segue uma distribuição exponencial. Assim sendo,</p>
<p>Podemos calcular o tempo médio de vida de uma célula por</p>
<blockquote>
<p>.
$$ \frac {196} {\lambda} = \frac {196} {2.5} = 78.4 \hspace{.5em} dias$$
.</p>
</blockquote>
<h3 id="b-a-vari%C3%A2ncia-do-tempo-de-vida">(b) A variância do tempo de vida</h3>
<p>A variância dessa distribuição exponencial é dada por</p>
<blockquote>
<p>.
$$ 196 \cdot \frac 1 {\lambda^2} = \frac{196}{(2.5)^2}
= 31.36  \hspace{.5em} dias ^2 $$
.</p>
</blockquote>
<h2 id="quest%C3%A3o-08">Questão 08</h2>
<p><STRONG> DERROTA </STRONG></p>
<h2 id="quest%C3%A3o-09">Questão 09</h2>
<p>Para um processo de Poisson $N(t)$ de intensidade $\lambda$ e dois tempos
fixos $t_1$ e $t_2$ , $t_1 &lt; t_2$ , encontre a função probabilidade
conjunta para duas variáveis aleatórias $N(t_1)$ e $N(t_2)$.</p>
<p>$$ Pr{N(t_1)=n_1, N(t_2)=n_2} = Pr{N(t_1)=n_1, N(t_2) - N(t_1) =n_2-n_1} $$
$$ Pr{N(t_1)=n_1, N(t_2)=n_2} = Pr{N(t_1)=n_1} \cdot Pr{N(t_2-t_1)=n_2-n_1} $$
$$ Pr{N(t_1)=n_1, N(t_2)=n_2} =
\frac{e^{-\lambda t_1}(\lambda t_1)^{n_1}}{n!} \cdot
\frac{
e^{-\lambda (t_1 - t_2)}(\lambda (t_1 - t_2))^{(n_2 - n_1)}
}{
(n_2 - n_1)!
}
$$</p>
<h2 id="quest%C3%A3o-10">Questão 10</h2>
<p>Partı́culas radioativas são emitidas de uma fonte de acordo com um processo de
Poisson de intensidade $\lambda = 1$ partıícula por minuto.</p>
<h3 id="t%C3%B3pico-a">Tópico A</h3>
<p>Suponha que cinco partículas são emitidas no primeiro minuto.
Qual é a probabilidade que exatamente duas dessas partículas foram emitidas nos
primeiros 30 segundos? (Resp.: 0.312).</p>
<hr>
<p>Usando minutos como nossa unidade de tempo, o que queremos calcular pode ser expresso por:
$$ Pr { N(0.5) = 2 | N(1) = 5} $$</p>
<p>Aplicando a fórmula de probabilidade condicional:
$$ Pr { A | B } = \frac {Pr { A, B }} {Pr { B }} $$
$$
Pr { N(0.5) = 2 | N(1) = 5}
= \frac {
Pr { N(0.5) = 2, N(1) = 5}
} {
Pr { N(1) = 5 }
}
$$</p>
<p>Para tornar os eventos independentes, vale:
$$
Pr { N(0.5) = 2 | N(1) = 5}
= \frac {
Pr { N(0.5) = 2, N(1 - 0.5) = 5 - 2}
} {
Pr { N(1) = 5 }
}
$$</p>
<p>Dessa forma,
$$
Pr { N(0.5) = 2 | N(1) = 5}
= \frac {
{ Pr { N(0.5) = 2 } \cdot Pr{ N(1 - 0.5) = 5 - 2 } }
} {
Pr { N(1) = 5 }
}
$$</p>
<p>$$
Pr { N(0.5) = 2 | N(1) = 5}
= \frac {
{ Pr { N(0.5) = 2 } \cdot Pr{ N(0.5) = 3 } }
} {
Pr { N(1) = 5 }
}
$$</p>
<p>Aplicando a fórmula do Processo de Poisson:
$$
Pr { N(t) = n}
= \frac {
e^{-\lambda t} (\lambda t)^n
} {
n!
}
$$</p>
<p>Para $n = 2$ :
$$
Pr{ N(0.5) = 2 }
= \frac {
e^{-1 \cdot \frac 1 2} (1 \cdot \frac 1 2)^2
} {
2!
}
= \frac { e^{-0.5} (0.5)^2 } { 2 }
= \frac {\frac 1 4 \sqrt{\frac 1 e}} {2}
= \frac {\sqrt{\frac 1 e}} {8}
\approx 0.07581633246407918
$$</p>
<p>Para $n = 3$ :
$$
Pr{ N(0.5) = 3 }
= \frac {
e^{-1 \cdot \frac 1 2} (1 \cdot \frac 1 2)^3
} {
3!
}
= \frac { \frac 1 8 \sqrt{\frac 1 e}  } { 6 }
= \frac { \sqrt{\frac 1 e} } { 48 }
\approx 0.012636055410679864
$$</p>
<p>Para calcular $Pr { N(1) = 5 }$ :
$$
Pr{ N(1) = 5 }
= \frac {
e^{-1 \cdot 1} (1 \cdot 1)^5
} {
5!
}
= \frac { e^{-1} \cdot 1^{5} } { 5! }
= \frac { 1 } { 120 e }
\approx 0.0030656620097620196
$$</p>
<p>Então
$$
Pr { N(0.5) = 2 | N(1) = 5}
= \frac {
\frac {\sqrt{\frac 1 e}} {8} \cdot \frac { \sqrt{\frac 1 e} } { 48 }
} {
\frac { 1 } { 120 e }
}
= \frac {\sqrt{\frac 1 e} \cdot \sqrt{\frac 1 e}} {8 \cdot 48 }
\cdot \frac { 120 e } { 1 }
= \frac {{\cancel e^{-1}} \cdot 120 \cancel e} {8 \cdot 48}
$$
$$
Pr { N(0.5) = 2 | N(1) = 5}
= \frac {120} {8 * 48}
= \frac {120} {384}
= \frac {5} {16}
$$</p>
<blockquote>
<p>.
$$
Pr { N(0.5) = 2 | N(1) = 5}
= \frac {5} {16}
= 0.3125
$$
.</p>
</blockquote>
<br>
<h3 id="t%C3%B3pico-b">Tópico B</h3>
<p>Seja $S_n$ o tempo de emissão da n−ésima partícula.
Expresse $S_n$ em termos do tempo de permanência no estado $n$,
isto é $T_n$ , e então encontre $E[S_n]$.
(Resp.: E[Sn ] = n)</p>
<hr>
<p>O tempo de emissão da n−ésima partícula ($S_n$ ) depende do tempo de
permanência no estado $T_n$ e do tempo de permanência nos estados anteriores,
ou seja:
$$ S_n = T_1 + T_2 + T_3 + \dots + T_{n-1} + T_n $$
$$ S_n = \sum _{i = 1} ^{n} T_i $$</p>
<p>Em uma distribuição de poisson, o tempo de emissão da n-ésima partícula segue
uma distribuição exponencial.
$$ T_n \sim Exp(\lambda) $$</p>
<p>Em uma distribuição exponencial $Exp(\lambda)$, podemos calcular a
média esperada (a esperança) por:
$$ E[T_n] = \frac 1 \lambda $$</p>
<p>Dado $\lambda = 1$, tem-se que:</p>
<p>$$ E[T_n] = 1 $$</p>
<p>Sabemos que se trata de um
<strong> processo de poisson homogêneo </strong>,
então podemos inferir que:
$$ E[T_i] = 1  \hspace{1em}  \forall , i$$</p>
<p>Assim, obtemos:
$$ E[S_n]
= E \left[
\sum _{i = 1} ^{n} T_i<br>
\right]
$$
$$ E[S_n]
= E \left[
\sum _{i = 1} ^{n} 1
\right]
$$</p>
<p>Usando a propriedade de soma de constantes:
$$ \sum _{i = 1} ^{n} C = C \cdot n $$</p>
<p>Temos então:
$$ E[S_n] = 1 \cdot n $$</p>
<br>
<p>Portanto, concluímos que:</p>
<blockquote>
<p>.
$$ E[S_n] = n $$
.</p>
</blockquote>
<br>
<h3 id="t%C3%B3pico-c">Tópico C</h3>
<p>Suponha que cada partícula sobreviva durante 10 segundos.
Qual é a probabilidade de k partıículas existirem em um minuto?
(Resp.: ≈ 0.84648/(6k k!))</p>
<hr>
<p>Dado que uma partícula sobrevive por 10 segundos, a probabilidade de,
após 1 min desde o início do experimento, existirem exatamante k partículas
depende tão somente do ocorrido nos</p>
<p>$$ Pr { N(60/60) - N(50/60) = k } = Pr { N(10/60) = k } $$
$$
Pr { N(t) = n}
= \frac {
e^{-\lambda t} (\lambda t)^n
} {
n!
}
$$
$$
Pr { N(1/6) = k }
= \frac {
e^{-1 \cdot \frac 1 6} (1 \cdot \frac 1 6)^k
} {
k!
}
= \frac {
e^{-\frac 1 6} (\frac 1 6)^k
} {
k!
}
= \frac {
\frac {1} {\sqrt[6]{e}} (\frac 1 6)^k
} {
k!
}
$$</p>
<p>$$
e ^ {- \frac 1 6}
= \frac 1 { \sqrt [6] e }
\approx 0.8464817248906141
\approx 0.84648
$$</p>
<p>$$
Pr { N(1/6) = k }
= \frac {
\frac {1} {\sqrt[6]{e}}
} {
k!
} \cdot \frac {1} {6^k}
\approx \frac {
0.8464817248906141
} {
k! \hspace{0.5em} 6^k
}
$$</p>
<br>
<blockquote>
<p>.
$$
Pr { N(1/6) = k }
\approx \frac { 0.84648 } { 6^k \hspace{0.25em} k!}
$$
.</p>
</blockquote>
<br>
<h2 id="quest%C3%A3o-11">Questão 11</h2>
<p>Seja ${N(t), t \neq 0}$ um processo de Poisson de taxa $\lambda$.
Para $s &lt; t$ encontre:</p>
<h3 id="a-pnt--ns-resp-1-%E2%88%92-e%E2%88%92%CE%BBt%E2%88%92s">(a) $P(N(t) &gt; N(s))$. (Resp: 1 − e−λ(t−s) )</h3>
<p>Observe que $P(N(t) &gt; N(s))$ é equivalente a $P(N(t) - N(s) &gt; 0)$.
Assim, Podemos calcular essa probabilidade da seguinte forma:</p>
<p>$$ Pr {N(t) - N(s) &lt; 0 } = 0 $$
$$ \therefore Pr {N(t) - N(s) &gt; 0 } = 1 - Pr {N(t) - N(s) \le 0 } $$</p>
<p>Considerando que $s &lt; t$, chegamos a
$$ Pr { N(s) &gt; N(t) } = 0 $$</p>
<p>Portanto
$$ Pr {N(t) - N(s) &gt; 0 } = 1 - Pr {N(t) - N(s) = 0 } $$</p>
<p>Sabendo que
$$ Pr { N(t) = k } = Pr { N(t + s) - N(s) = k } $$</p>
<p>Então podemos afirmar que $N(t) - N(s)$ descreve a quantidade de eventos que
ocorrem no intervalo $(, t - s, \hspace{0.333em} t ,]$, assim sendo:
$$ Pr {N(t) - N(s) = 0 } = Pr {N(t - s) = 0 } $$</p>
<p>$$
Pr {N(t - s) = 0 }
= \frac {
e^{-\lambda (t - s)} \cdot [\lambda (t - s)]^0
} {
0!
}
$$</p>
<p>$$ Pr {N(t - s) = 0 } = \frac {e^{-\lambda (t - s)} \cdot 1} {1} $$
$$ Pr {N(t - s) = 0 } = e^{-\lambda (t - s)} $$</p>
<br>
<p>Substituindo o valor de Pr {N(t) - N(s) = 0 }, obtemos o resultado:</p>
<blockquote>
<p>.
$$ Pr {N(t) &gt; N(s) } = 1 - e^{-\lambda (t - s)} $$
.</p>
</blockquote>
<h3 id="b-pns--0-nt--3-resp-e%E2%88%92%CE%BBs-e%E2%88%92%CE%BBt%E2%88%92s-%CE%BBt-%E2%88%92-s3-3">(b) $P(N(s) = 0, N(t) = 3)$ (Resp.: e−λs e−λ(t−s) [λ(t − s)]3 /3!)</h3>
<p>A priori, precisamos tornar os eventos independentes:
$$ Pr { N(s) = 0, N(t) = 3} = Pr { N(s) = 0, N(t - s) = 3 - 0} $$</p>
<p>Assim, chegamos a:
$$ Pr { N(s) = 0, N(t) = 3}
= Pr { N(s) = 0 } \cdot Pr { N(t - s) = 3}
$$</p>
<p>$$ Pr { N(s) = 0 }
= \frac {e^{-\lambda s} (\lambda s)^0} {0!}
= e^{-\lambda s}
$$</p>
<p>$$ Pr { N(t - s) = 3}
= \frac {e^{-\lambda (t - s)} \cdot [\lambda (t - s)]^3} {3!}
$$</p>
<p>Logo
$$ Pr { N(s) = 0, N(t) = 3 }
= e^{-\lambda s}
\cdot {e^{-\lambda (t - s)}
\cdot [\lambda (t - s)]^3}
\cdot \frac{1}{3!}
$$</p>
<p>Conclui-se, então,</p>
<blockquote>
<p>.
$$ Pr { N(s) = 0, N(t) = 3}
= e^{-\lambda (t - 2s)} \cdot [\lambda (t - s)]^3 \cdot \frac{1}{6} $$
.</p>
</blockquote>
<h3 id="c-entns--4-resp-4--%CE%BBt-%E2%88%92-s">(c) $E[N(t)|N(s) = 4]$ (Resp.: 4 + λ(t − s))</h3>
<p>Usando a propriedade dos incrementos independentes do processo de Poisson,
temos:
$$ E[N(t)|N(s) = 4] = 4 + E[N(t) - N(s)] $$</p>
<p>Dado que $N(t) - N(s)$ é igual a $N(t - s)$, podemos escrever:
$$ E[N(t)|N(s) = 4] = 4 + E[N(t - s)] $$</p>
<p>A esperança do processo de Poisson é dada por:
$$ E[N(t)] = \lambda t $$</p>
<p>Portanto, chegamos à conclusão de que:
$$ E[N(t)|N(s) = 4] = 4 + \lambda * (t-s) $$</p>
<br>
<h3 id="d-ensnt--4-resp-4st">(d) $E[N(s)|N(t) = 4]$ (Resp.: 4s/t)</h3>
<p>Aplicando o somatório para calcular a esperança
<input type="checkbox" id="checkbox0" checked="true"><label for="checkbox0">= \sum _{x} , x \cdot Pr{X = x} $$</label></p>
<p>Obtém-se
$$ E[N(s) | N(t) = 4]
= \sum _{i = 0} ^ {4}
i \cdot Pr{ N(s) = i | N(t) = 4 }
$$</p>
<p>$$ Pr{ N(s) = i | N(t) = 4 }
= \frac {
Pr{ N(s) = i, N(t) = 4 }
} {
Pr{ N(t) = 4 }
}
$$</p>
<p>Note que $s$ e $t$ não configuram intervalos disjuntos,
por esse motivo, aplicamos
$$ Pr{ N(s) = i, N(t) = 4 }
= Pr{ N(s) = i, N(t - s) = 4 - i }
= Pr{ N(s) = i} \cdot Pr{ N(t - s) = 4 - i }
$$</p>
<p>$$ Pr{ N(s) = i | N(t) = 4 }
= \frac {
Pr{ N(s) = i} \cdot Pr{ N(t - s) = 4 - i }
} {
Pr{ N(t) = 4 }
}
$$</p>
<p>$$ Pr{ N(s) = i | N(t) = 4 }
= \frac {e^{-\lambda s}(\lambda s)^i} {i!}
\cdot \frac {e^{-\lambda (t - s)}[\lambda (t - s)]^{4-i}} {(4-i)!}
\cdot \frac {4!} {e^{-\lambda t}(\lambda t)^4}
$$</p>
<p>$$ Pr{ N(s) = i | N(t) = 4 }
= \frac {\cancel{e^{-\lambda s}}(\lambda s)^i} {i!}
\cdot \frac {
\cancel{e^{-\lambda t}}
\cancel{e^{\lambda s}}
[\lambda t - \lambda s]^{4-i}
} {(4-i)!}
\cdot \frac {4!} {\cancel{e^{-\lambda t}}(\lambda t)^4}
$$</p>
<p>$$ Pr{ N(s) = i | N(t) = 4 }
= \frac {
4! (\lambda s)^i [\lambda(t-s)]^{4-i}
} {
\lambda^4 t^4 (4-i)! i!
}
$$</p>
<p>Como $\lambda$, $i$, $s$ e $t$ são positivos
(ignorando o caso $i$ = 0, pois ele não afetará a esperança)
$$ Pr{ N(s) = i | N(t) = 4 }
= \frac {
4! \lambda^i s^i \lambda^{4-i} (t-s)^{4-i}
} {
\lambda^4 t^4 (4-i)! i!
}
= \frac {
4! \cancel{\lambda^{i+4-i}} s^i (t-s)^{4-i}
} {
\cancel{\lambda^4} t^4 (4-i)! i!
}
$$</p>
<p>$$ Pr{ N(s) = i | N(t) = 4 }
= \frac {
4! s^i (t-s)^{4-i}
} {
t^4 (4-i)! i!
}
$$</p>
<p>$$ Pr{ N(s) = i | N(t) = 4 }
= \frac {
s^i (t-s)^{4-i}
} {
t^4
} \cdot \frac {4!} {(4-i)! i!}
$$</p>
<p>$$ Pr{ N(s) = i | N(t) = 4 }
= \frac {
s^i (t-s)^{4-i}
} {
t^4
} \cdot \binom{4}{i}
$$</p>
<p>$$ Pr{ N(s) = i | N(t) = 4 }
= \frac{1}{t^4} [s^i , (t - s)^{4-i} , \binom{4}{i}]
$$</p>
<p>$$ E[N(s) | N(t) = 4]
= \sum _{i = 0} ^ {4}
i \cdot \frac{1}{t^4} [s^i , (t - s)^{4-i} , \binom{4}{i}]
$$</p>
<p>$$ E[N(s) | N(t) = 4]
= \frac{1}{t^4} \sum _{i = 0} ^ {4}
i \cdot  [s^i , (t - s)^{4-i} , \binom{4}{i}]
$$</p>
<p>Expandindo o somatório</p>
<p>$$ \sum _{i = 0} ^ {4} i \cdot  [s^i , (t - s)^{4-i} , \binom{4}{i}]
= 4s^4 + 12s^3(t-s) + 12s^2(t-s)^2 + 4s(t-s)^3
$$</p>
<p>Expandindo novamente
$$
= 4s^4
+ (12s^3t-12s^4)
+ (12s^2t^2 - 24s^3t + 12s^4)
+ (- 4s^4 + 12s^3t - 12s^2t^2 + 4st^3)
$$</p>
<p>Reorganizando os termos
$$
= (4s^4 - 4s^4 -12s^4 + 12s^4)
+ (12s^3t - 24s^3t + 12s^3t)
+ (12s^2t^2 - 12s^2t^2)
+ 4st^3
$$</p>
<p>$$
= \cancel{(4s^4 - 4s^4 -12s^4 + 12s^4)}
+ \cancel{(12s^3t - 24s^3t + 12s^3t)}
+ \cancel{(12s^2t^2 - 12s^2t^2)}
+ 4st^3
$$</p>
<p>$$ \sum _{i = 0} ^ {4} i \cdot  [s^i , (t - s)^{4-i} , \binom{4}{i}]
= 4st^3
$$</p>
<p>Substituindo o resultado do somatório na equação da esperança obtem-se:
$$ E[N(s) | N(t) = 4]
= \frac{1}{t^4} \cdot 4st^3
$$</p>
<p>Portanto,</p>
<blockquote>
<p>.
$$ E[N(s) | N(t) = 4] = \frac{4s}{t} $$
.</p>
</blockquote>
<br>
<h2 id="quest%C3%A3o-12">Questão 12</h2>
<p>Um médico tem duas consultas a fazer, umas às 13h e outra às 13:30h.
O tempo gasto em cada consulta tem distribuição exponencial
com média de 30 minutos.
Assumindo que ambos os pacientes chegaram no horário marcado,
encontre o tempo médio gasto pelo paciente marcado às 13:30h no consultório.</p>
<hr>
<p>Seja $T_n$ a duração da n-ésima consulta</p>
<p>$$ E[T_n] = \frac 1 {\lambda} = 30 ,,, \iff \lambda = \frac 1 {30}$$
$$ T_n \sim Exp \left( \frac 1 {30} \right) $$
$$ Pr{T_n = t} = \lambda e^{-\lambda t} = \dfrac {e^{-t , / , 30}} {30} $$</p>
<p>Sendo $T_1$ o tempo de duração da primeira consulta. Como o segundo paciente
chega exatamente às 13:30, o tempo de espera será zero se a duração da primeira
consulta for menor ou igual a 30 min. Portanto, o tempo médio gasto pelo segundo
paciente ($X$) é dado por
<input type="checkbox" id="checkbox1" checked="true"><label for="checkbox1">= E[T_2] + E[A] $$</label></p>
<p>Sendo $A$ uma igual ao atraso,
o tempo extra tomado durante a primeira consulta.
Assim, é fácil notar que a $A$ pode ser definida em termos de $T_1$</p>
<p>$$ A = f_a(T_1) $$</p>
<p>$$ f_a(x) =
\begin{cases}
0 ,, , \hspace{1em} \text{se } ,, x \le \lambda
\
x - \lambda ,, , \hspace{1em} \text{se } ,, x &gt; \lambda
\end{cases}
$$</p>
<p>Dessa forma,</p>
<p>$$ E[A] = \int _0 ^{\infty} f_a(t) \cdot Pr { f_a(x) = t} dt$$</p>
<p>Aplicando a propriedade:
$$
\int _a ^c f(x) dx = \int _a ^b f(x) dx + \int _b ^c f(x) dx
\
a &lt; c &lt; c
$$</p>
<p>Chegamos a
$$ E[A] =
\int _{0} ^{\lambda} 0 \cdot Pr { T_1 = t } dt
+ \int _{\lambda} ^{\infty} (t - \lambda) \cdot (Pr { T_1 = t }) dt
$$</p>
<p>$$ E[A] = \int _{30} ^{\infty} t \cdot \dfrac {e^{-t/30}dt} {30} $$
$$ E[A] = \frac{1}{30}
\cdot \left. \left[
-30te^{-t/30} + C
\right]\right| _{30} ^{\infty}
$$</p>
<p>$$ E[A] = \frac{30}{30}
\cdot \lim_{x \to \infty} \left[
\left( - \frac x {e^{x/30}} \right)
-
\left( - \frac {30} e \right)
\right]
$$</p>
<p>$$ E[A] = 0 - \left( - \frac {30} e \right) = \frac{30}{e}$$
$$ E[A] \approx 11.03638323514327 $$</p>
<p>Voltando ao cálculo da média do tempo esperado no consultório
<input type="checkbox" id="checkbox2" checked="true"><label for="checkbox2">= E[T_2] + E[A] = \frac{1}{\lambda} + \frac {30} e</label>
\approx 30 + 11.03638323514327
$$</p>
<p>Conclui-se, então,</p>
<blockquote>
<p>.
<input type="checkbox" id="checkbox3" checked="true"><label for="checkbox3">\approx 41.036 $$</label>
.</p>
</blockquote>
<br>
<h2 id="quest%C3%A3o-13">Questão 13</h2>
<p>Imagine que pessoas entram numa sala de aula seguindo um processo de Poisson com taxa λ = 1 pessoa por minuto.</p>
<h3 id="a-qual-%C3%A9-o-tempo-esperado-at%C3%A9-que-a-d%C3%A9cima-pessoa-entre">(a) Qual é o tempo esperado até que a décima pessoa entre?</h3>
<p>O tempo esperado até a décima pessoa é dado pela integral
$$ E[w_{10}] = \int <em>0 ^\infty t f</em>{w_{10}} (t) dt $$</p>
<p>Dada a função densidade de probabilidade:
$$ f_{w_{n}} (t) = \frac {\lambda^n t^{n-1}} {(n-1)!} e^{-\lambda t} $$
$$ f_{w_{10}} (t) = \frac {\lambda^{10} t^{10-1}} {(10-1)!} e^{-\lambda t} $$
$$ f_{w_{10}} (t) = \frac {\lambda^{10} t^9} {9!} e^{-\lambda t} $$</p>
<p>Chegamos a
$$ E[w_{10}] = \int _0 ^\infty t \frac {\lambda^{10} t^9} {9!} e^{-\lambda t}dt $$</p>
<p>$$ E[w_{10}]
= \frac{\lambda^{10}}{9!}
\int _0 ^\infty
t^{10} e^{-\lambda t}dt
$$</p>
<p>$$ E[w_{10}]
= \frac{1^{10}}{9!}
\int _0 ^\infty
e^{-1t} t^{10} dt
$$</p>
<p>$$ E[w_{10}]
= \frac{1}{362880}
\int _0 ^\infty
t^{10} e^{-t}dt
$$</p>
<p>Podemos aplicar
$$ \int f d g = fg - \int g d f $$</p>
<p>com<br>
$$
f = t^{10}
\hspace{5em} dg = e^{-t}dt
\ df = 10 t^{9} dt
\hspace{5em} g = -e^{-t}
$$</p>
<p>Para obter:
$$ E[w_{10}]
= \left. -\frac{e^{-t}t^{10}}{362880} \right| _0 ^{\infty}
+ \frac {10} {362880}
\int _0 ^\infty
t^{9} e^{-t}dt
$$</p>
<p>$$ \lim _{x \to 0} - \frac{e^{-x}x^{10}}{362880} = 0 $$</p>
<p>$$ E[w_{10}]
= \frac {1} {36288}
\int _0 ^\infty
t^{9} e^{-t}dt
$$</p>
<p>Essa etapa é repetida múltiplas vezes até obtermos:</p>
<p>$$ E[w_{10}]
= 10 \int _0 ^\infty t e^{-t}dt
= \left. -10 e^{-t} t \right| _0 ^{\infty}
+ 10 \int _0 ^{\infty} e^{-t}dt
$$</p>
<p>$$ E[w_{10}]
= 10 \int _0 ^{\infty} e^{-t}dt
= \left. -10 e^{-t} \right| _0 ^{\infty}
= (-10 e^{-\infty} - (-10 e^{-0}))
$$</p>
<br>
<p>quando $t$ tende ao infinito, $e^{-t}$ tende a zero,
portanto $e^{-\infty} = 0$. Portanto</p>
<blockquote>
<p>.
$$ E[w_{10}] = 10 $$
.</p>
</blockquote>
<br>
<h3 id="b-qual-%C3%A9-a-probabilidade-de-que-o-tempo-entre-a-entrada-da-d%C3%A9cima-e-d%C3%A9cima-primeira-pessoa-seja-maior-do-que-dois-minutos-resp-%E2%89%88-0133">(b) Qual é a probabilidade de que o tempo entre a entrada da décima e décima primeira pessoa seja maior do que dois minutos? (Resp.: ≈ 0.133)</h3>
<p>$$ T_n ~ Exp(\lambda) $$</p>
<p>$$ T_{11} = w_{11} - w_{10} $$</p>
<p>$$ Pr{T_{11} &gt; t} = e ^ (- \lambda t) $$</p>
<p>$$ Pr{T_{11} &gt; 2} = e ^ (-1 \cdot 2) = e^{-2} \approx 0.1353352832366127 $$</p>
<blockquote>
<p>.
$$ Pr{T_{11} &gt; 2} \approx 0.135 $$
.</p>
</blockquote>
<h2 id="quest%C3%A3o-14">Questão 14</h2>
<p>Passageiros chegam a um terminal rodoviário de acordo com um processo de Poisson de taxa λ = 8
passageiros por hora. O número de horas entre a chegada de ônibus sucessivos nesse terminal é
distribuı́do uniformemente entre 0 e 1. Imagine que um ônibus tenha acabado de partir. Seja X o
número de pessoas que entrarão no próximo ônibus. Calcule E[X]. (Resp.: 4).</p>
<hr>
<p>Podemos calcular o tempo esperado para a chegada do próximo ônibus como
$$E[O(t)]= 0 + 12 = \frac 1 2 $$</p>
<p>$$ E[Passageiros(t)]= t\lambda $$</p>
<p>$$ E[P(t)/O(t)] = E[Passageiros(E[O(t)])] = \frac 8 2 =4 $$</p>
<h2 id="quest%C3%A3o-15">Questão 15</h2>
<p>Os tempos de vida de um cachorro (Tc ) e de um gato (T g ) são variáveis aleatórias independentes,
distribuı́das de acordo com distribuições exponenciais de parâmetros λc e λ g , respectivamente.
Suponha que um dos pets tenha acabado de morrer. Calcule o valor esperado do tempo de
vida adicional do outro pet. Dica: Veja na seção 5.2.3 do livro do Sheldon Ross como calcular a
probabilidade Pr{X1 &lt; X2 }</p>
<hr>
<p>Sendo
$$
t_c \sim Exp(\lambda_c)
\hspace{5em}
t_g \sim Exp(\lambda_g)
$$</p>
<p>Então, o Tempo de vida esperado é dado por
$$
t_c = \frac{1}{\lambda_c}
\hspace{5em}
t_g = \frac{1}{\lambda_g}
$$</p>
<p>Sabendo se tratar de uma distribuição exponencial, aplicamos a propriedade da
ausência de memória: ou seja, a morte de um não afeta o tempo esperado da vida
do outro.</p>
<p>Assim, podemos aplicar a fórmula
$$ Pr{S_a &lt; S_b } = \frac{\lambda_a}{\lambda_a + \lambda_b} $$</p>
<p>Para calcular o tempo de vida adicional ($V$):</p>
<p>$$ V = E[T_g|T_g&gt;T_c]⋅P{T_c &lt; T_g}+E[T_c |T_c &gt; T_g] \cdot P{T_g &lt; T_c} $$</p>
<p>$$ V =
\left(
\frac{\lambda_g}{\lambda_c+\lambda_g} \cdot \frac{1}{\lambda_c}
\right) + \left(
\frac{\lambda_c}{\lambda_c+\lambda_g} \cdot \frac{1}{\lambda_g}
\right)
$$</p>
<p>Resposta:</p>
<blockquote>
<p>.
$$ V =
\frac{\lambda_g}{\lambda_c+\lambda_g} \cdot \frac{1}{\lambda_c}
+
\frac{\lambda_c}{\lambda_c+\lambda_g} \cdot \frac{1}{\lambda_g}
$$
.</p>
</blockquote>

</body>
</html>
